{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ffa1607e6144f498f8499a7ab0779e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b9daa269e5f4b5eabe882dbeeedd657",
              "IPY_MODEL_fe4004c6cca445e38770044410867ab1",
              "IPY_MODEL_33bbbdc9cb9e45789f375e6569bad2bc"
            ],
            "layout": "IPY_MODEL_fbbfaa428fa245368158f0c59448178d"
          }
        },
        "4b9daa269e5f4b5eabe882dbeeedd657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b8510490ecb41ba9ea0283e18c90cca",
            "placeholder": "​",
            "style": "IPY_MODEL_aaca3dc7291e4a19b30c911da2941830",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "fe4004c6cca445e38770044410867ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_843c63626fe24e8c8790a47335a9af0d",
            "max": 434,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bb7fb952300404f82639adfb2e6a16f",
            "value": 434
          }
        },
        "33bbbdc9cb9e45789f375e6569bad2bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c261d17bb474c26ac77b9d1a6846834",
            "placeholder": "​",
            "style": "IPY_MODEL_67210958e5dd4f7cac46bb10ebf646a6",
            "value": " 434/434 [00:00&lt;00:00, 18.1kB/s]"
          }
        },
        "fbbfaa428fa245368158f0c59448178d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b8510490ecb41ba9ea0283e18c90cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaca3dc7291e4a19b30c911da2941830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "843c63626fe24e8c8790a47335a9af0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bb7fb952300404f82639adfb2e6a16f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c261d17bb474c26ac77b9d1a6846834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67210958e5dd4f7cac46bb10ebf646a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87344ab44ed64279bd364da64ca8b432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52a2a8cf98f947acbbcf3742d32eb8a6",
              "IPY_MODEL_968d0cd48aba4694baadbd48c6155680",
              "IPY_MODEL_ff2a059a852c4948a09e9e668f3dbbbf"
            ],
            "layout": "IPY_MODEL_c3852507790d46b9962f90748f7b8d66"
          }
        },
        "52a2a8cf98f947acbbcf3742d32eb8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcd3314592e3464aab1ad956e859b921",
            "placeholder": "​",
            "style": "IPY_MODEL_3566b51c17514015a9384c1752d19d12",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "968d0cd48aba4694baadbd48c6155680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c50fa130948f48c5b941f321dcb31e30",
            "max": 1215509,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00eb31fca57541298224d0a2fbeeb191",
            "value": 1215509
          }
        },
        "ff2a059a852c4948a09e9e668f3dbbbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffd5c24776d940fdbf25c27b11f3e0a3",
            "placeholder": "​",
            "style": "IPY_MODEL_37b48799bd1b4655a49ed40cc47204d4",
            "value": " 1.22M/1.22M [00:00&lt;00:00, 9.48MB/s]"
          }
        },
        "c3852507790d46b9962f90748f7b8d66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcd3314592e3464aab1ad956e859b921": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3566b51c17514015a9384c1752d19d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c50fa130948f48c5b941f321dcb31e30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00eb31fca57541298224d0a2fbeeb191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffd5c24776d940fdbf25c27b11f3e0a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37b48799bd1b4655a49ed40cc47204d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca35bbadafcd45cfab4ff6753fa35c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe1f09163e41493dabaa40bc946c03d1",
              "IPY_MODEL_82c11f6a5aac41f9be8b2a45b6b17f63",
              "IPY_MODEL_4c60271f80294bf2b1e7e6f25f490c4a"
            ],
            "layout": "IPY_MODEL_bd594f56528940f8bc8ff3720e42dd8a"
          }
        },
        "fe1f09163e41493dabaa40bc946c03d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1abdb760c49c4ab892004104bec87b82",
            "placeholder": "​",
            "style": "IPY_MODEL_796ed41209c74fd785c5b10037782751",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "82c11f6a5aac41f9be8b2a45b6b17f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d5dab61926246e0a0782407f678c43a",
            "max": 654186735,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a373e7f21deb466a88c75d3533502b5f",
            "value": 654186735
          }
        },
        "4c60271f80294bf2b1e7e6f25f490c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_990bd7d2e40646389559494eb418f73f",
            "placeholder": "​",
            "style": "IPY_MODEL_14a2c3b19934441288f7be2b179d1edd",
            "value": " 654M/654M [00:15&lt;00:00, 44.5MB/s]"
          }
        },
        "bd594f56528940f8bc8ff3720e42dd8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1abdb760c49c4ab892004104bec87b82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "796ed41209c74fd785c5b10037782751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d5dab61926246e0a0782407f678c43a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a373e7f21deb466a88c75d3533502b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "990bd7d2e40646389559494eb418f73f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14a2c3b19934441288f7be2b179d1edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install owlready2\n",
        "!pip install rdflib\n",
        "from owlready2 import *\n",
        "import rdflib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNz7qH_u8R82",
        "outputId": "a99a9b8b-4469-45c0-9416-b24b5d331157"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting owlready2\n",
            "  Downloading Owlready2-0.43.tar.gz (27.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.4/27.4 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: owlready2\n",
            "  Building wheel for owlready2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for owlready2: filename=Owlready2-0.43-cp310-cp310-linux_x86_64.whl size=24154536 sha256=5b48c57176bc367476d0aec2653ad6baa9f2b5214cdfc737d81b5e7788e32353\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/9b/82/c07844dfbaa52dbf3352b18b0a27c348ee854df8b752990c53\n",
            "Successfully built owlready2\n",
            "Installing collected packages: owlready2\n",
            "Successfully installed owlready2-0.43\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isodate<0.7.0,>=0.6.0 (from rdflib)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib) (3.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib) (1.16.0)\n",
            "Installing collected packages: isodate, rdflib\n",
            "Successfully installed isodate-0.6.1 rdflib-6.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu4pcM2M7h4D",
        "outputId": "fac6bcc5-5598-4b51-a509-b7aad9aca745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "قانون سنوات ارشد مقطع تحصیلی ارشد.\n",
            "قانون آموزش محور برای ارشد نام قانون قانون آموزش محور برای ارشد.\n",
            "رویداد زبان شناسی زمان رویداد زمستان 1400.\n",
            "دکتر شمس فرد نام شخص مهرنوش.\n",
            "کتاب راسل موجود است در کتابخانه مرکزی دانشکده بهشتی.\n",
            "قانون مرتبط با پایان نامه ارشد وضع میشود برای دانشگاه شهیدبهشتی.\n",
            "دانشکده کامپیوتر بهشتی گروه آموزشی دانشکده هوش مصنوعی.\n",
            "سایت کتابخانه مرکزی نوع تارنما آموزشی.\n",
            "کلاس 104 دانشکده کامپیوتر آدرس مکان ولنجک- دانشگاه بهشتی- دانشکده کامپیوتر.\n",
            "قانون شهریه ثابت ارشد وضع میشود برای دانشگاه شهیدبهشتی.\n",
            "قانون مرتبط با پایان نامه ارشد ورودی سال 1400.\n",
            "آزمایشگاه پردازش زبان طبیعی نام آزمایشگاه آزمایشگاه پردازش زبان طبیعی.\n",
            "دانشگاه شهیدبهشتی محل کار است برای دکتر شمس فرد.\n",
            "دکتر عبدوس نام خانوادگی عبدوس.\n",
            "قانون ثبت نام ارشد وضع میشود برای دانشگاه شهیدبهشتی.\n",
            "دانشکده کامپیوتر بهشتی نام مکان دانشکده کامپیوتر.\n",
            "قانون مشروطی در ارشد معدل مشروطی کمتر از 14.\n",
            "دانشگاه شهیدبهشتی نام دانشگاه شهید بهشتی.\n",
            "کتابخانه مرکزی دانشکده بهشتی نام مکان کتابخانه مرکزی دانشگاه بهشتی.\n",
            "قانون مشروطی در ارشد حداکثر تعداد مشروطی یک ترم.\n",
            "قانون سنوات ارشد نام قانون قانون سنوات برای ارشد.\n",
            "سایت کتابخانه مرکزی متعلق است به کتابخانه مرکزی دانشکده بهشتی.\n",
            "درس هوش مصنوعی در ترم دوم سال 1401 ترمی که درس ارائه میشود 140102.\n",
            "قانون سنوات ارشد وضع میشود برای دانشگاه شهیدبهشتی.\n",
            "دفتر دکتر قوامی زاده نام دفتر دفتر دکتر قوامی زاده.\n",
            "دکتر شمس فرد تدریس میکند درس هوش مصنوعی در ترم دوم سال 1401.\n",
            "معاونت آموزشی دانشکده کامپیوتر بهشتی نقش معاون آموزشی دانشکده کامپیوتر.\n",
            "دکتر عبدوس نام شخص منیره.\n",
            "دانشکده کامپیوتر بهشتی گروه آموزشی دانشکده شبکه.\n",
            "سایت دانشکده نوع تارنما آموزشی.\n",
            "قانون شهریه ثابت ارشد مهلت پرداخت قبل از ثبت نام.\n",
            "سایت دانشکده متعلق است به دانشکده کامپیوتر بهشتی.\n",
            "دکتر سلیمی بدر تدریس میکند درس هوش مصنوعی در ترم دوم سال 1402.\n",
            "قانون ثبت نام ارشد حداقل واحد 8.\n",
            "دکتر شمس فرد حوزه تحقیق پردازش زبان طبیعی-هستان شناسی-مهندسی دانش و سیستم های دانش پایه-وب معنایی-هوش مصنوعی.\n",
            "قانون شهریه ثابت ارشد نام قانون شهریه ثابت ارشد دوره پردیس.\n",
            "درس هوش مصنوعی در ترم دوم سال 1401 تعداد واحد درس 3.\n",
            "قانون فارغ التحصیلی حداقل تعداد دروس اصلی 4.\n",
            "کتابخانه مرکزی دانشکده بهشتی آدرس مکان تهران ولنجک دانشگاه شهید بهشتی کتابخانه مرکزی.\n",
            "دکتر شمس فرد گروه آموزشی شخص هوش مصنوعی.\n",
            "دانشکده کامپیوتر بهشتی آدرس مکان ولنجک - دانشگاه بهشتی - دانشکده کامپیوتر.\n",
            "قانون ثبت نام ارشد حداکثر واحد 14.\n",
            "سایت دانشکده فرم آموزشی فرم انتخاب استاد راهنما ارشد.\n",
            "کتاب راسل منبع است برای درس هوش مصنوعی در ترم دوم سال 1401.\n",
            "قانون خوابگاه برای پردیس دوره پردیس.\n",
            "قانون آموزش محور برای ارشد مقطع تحصیلی ارشد.\n",
            "کتابخانه مرکزی دانشکده بهشتی دارد تارنما سایت کتابخانه مرکزی.\n",
            "قانون مرتبط با پایان نامه ارشد مقطع تحصیلی ارشد.\n",
            "دکتر قوامی زاده نام خانوادگی قوامی زاده.\n",
            "دکتر شمس فرد کار میکند در دانشگاه شهیدبهشتی.\n",
            "معاونت آموزشی دانشکده کامپیوتر بهشتی زمان فعالیت اجرایی از سال 1398تاکنون.\n",
            "قانون فارغ التحصیلی مقطع تحصیلی ارشد.\n",
            "قانون شهریه ثابت ارشد مبلغ شهریه 59000000 ریال.\n",
            "کلاس 104 دانشکده کامپیوتر نام مکان کلاس 104 دانشکده کامپیوتر.\n",
            "دکتر شمس فرد نام خانوادگی شمس‌ فرد.\n",
            "قانون مرخصی گرفتن ارشد تعداد ترم 1.\n",
            "درس هوش مصنوعی در ترم دوم سال 1401 نام درس هوش مصنوعی.\n",
            "دفتر دکتر قوامی زاده طبقه 4.\n",
            "دکتر شمس فرد محل فارغ التحصیلی دانشگاه صنعتی امیرکبیر.\n",
            "درس هوش مصنوعی در ترم دوم سال 1402 برگزار میشود در کلاس 104 دانشکده کامپیوتر.\n",
            "دفتر دکتر قوامی زاده ساعت حضور شنبه تا سه شنبه ساعت هشت تا نه.\n",
            "دکتر سلیمی بدر نام شخص آرمین.\n",
            "دفتر دکتر شمس فرد مکان حضور است برای دکتر شمس فرد.\n",
            "دفتر دکتر شمس فرد ساعت حضور شنبه‌ها از ساعت  ده تا دوازده، چهارشنبه‌ها از ساعت سه تا پنج.\n",
            "دفتر دکتر قوامی زاده مکان حضور است برای دکتر قوامی زاده.\n",
            "دفتر دکتر شمس فرد آدرس مکان ولنجک - دانشگاه بهشتی- دانشکده کامپیوتر.\n",
            "رویداد زبان شناسی محل سخرانی است برای دکتر شمس فرد.\n",
            "قانون مرخصی گرفتن ارشد نام قانون قانون مرخصی گرفتن برای ارشد.\n",
            "قانون خوابگاه برای پردیس وضع میشود برای دانشگاه شهیدبهشتی.\n",
            "قانون آموزش محور برای ارشد وضع میشود برای دانشگاه شهیدبهشتی.\n",
            "رویداد زبان شناسی نام رویداد کاربرد پیکره ها در برابر بررسی های زبانی و شناختی.\n",
            "دفتر دکتر قوامی زاده آدرس مکان ولنجک - دانشگاه بهشتی - دانشکده کامپیوتر.\n",
            "آزمایشگاه پردازش زبان طبیعی مکان تحقیق است برای دکتر شمس فرد.\n",
            "قانون فارغ التحصیلی وضع میشود برای دانشگاه شهیدبهشتی.\n",
            "معاونت آموزشی دانشکده کامپیوتر بهشتی منصوب میشود به دکتر قوامی زاده.\n",
            "درس هوش مصنوعی در ترم دوم سال 1402 نام درس هوش مصنوعی.\n",
            "دکتر عبدوس گروه آموزشی شخص هوش مصنوعی.\n",
            "دکتر قوامی زاده نام شخص رامک.\n",
            "دفتر دکتر شمس فرد نام دفتر دفتر دکتر شمس فرد.\n",
            "قانون مرخصی گرفتن ارشد مقطع تحصیلی ارشد.\n",
            "دکتر عبدوس تدریس میکند درس هوش مصنوعی در ترم دوم سال 1402.\n",
            "کلاس 104 دانشکده کامپیوتر طبقه 1.\n",
            "قانون فارغ التحصیلی نام قانون قانون فارغ تحصیلی برای ارشد.\n",
            "سایت کتابخانه مرکزی نام تارنما سایت کتابخانه مرکزی دانشگاه بهشتی.\n",
            "دکتر شمس فرد آخرین مدرک اخذ شده دکتری.\n",
            "دکتر سلیمی بدر نام خانوادگی سلیمی بدر.\n",
            "قانون مرخصی گرفتن ارشد وضع میشود برای دانشگاه شهیدبهشتی.\n",
            "دفتر دکتر شمس فرد طبقه 4.\n",
            "قانون شهریه ثابت ارشد دوره پردیس.\n",
            "قانون فارغ التحصیلی تعداد واحد مورد نیاز برای فارغ التحصیلی 32.\n",
            "دانشکده کامپیوتر بهشتی گروه آموزشی دانشکده نرم افزار.\n",
            "دکتر شمس فرد شماره تلفن 29904171.\n",
            "قانون آموزش محور برای ارشد تعریف آموزش محور اگر تا آخر ترم سه، هجده واحد گذرانده نشود، دانشجوی کارشناسی  ارشد، آموزش محور میشود.\n",
            "دکتر سلیمی بدر گروه آموزشی شخص هوش مصنوعی.\n",
            "قانون ثبت نام ارشد نام قانون قانون ثبت نام برای ارشد.\n",
            "قانون مرتبط با پایان نامه ارشد نام قانون قانون پایان نامه برای ارشد.\n",
            "قانون سنوات ارشد تعداد ترم 5.\n",
            "قانون مشروطی در ارشد وضع میشود برای دانشگاه شهیدبهشتی.\n",
            "کتاب راسل نام منبع کتاب راسل.\n",
            "قانون ثبت نام ارشد مقطع تحصیلی ارشد.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from rdflib import Graph, Namespace\n",
        "\n",
        "\n",
        "g = Graph()\n",
        "g.parse(\"/content/uni_rdf(1).rdf\", format=\"xml\")\n",
        "\n",
        "# Define the ontology namespace\n",
        "uni_ns = Namespace(\"http://www.semanticweb.org/sepideh/ontologies/2023/5/university-ontology#\")\n",
        "\n",
        "\n",
        "def contains_english(sentence):\n",
        "    english_words_pattern = re.compile(r'[a-zA-Z]')\n",
        "    return bool(english_words_pattern.search(sentence))\n",
        "\n",
        "\n",
        "filtered_sentences = []\n",
        "for subject, predicate, obj in g:\n",
        "\n",
        "    subject = str(subject).replace(uni_ns, \"\")\n",
        "    predicate = str(predicate).replace(uni_ns, \"\")\n",
        "    obj = str(obj).replace(uni_ns, \"\")\n",
        "\n",
        "\n",
        "    sentence = f\"{subject} {predicate} {obj}.\"\n",
        "\n",
        "\n",
        "    if not contains_english(sentence):\n",
        "        # Replace underscores with spaces\n",
        "        sentence = sentence.replace(\"_\", \" \")\n",
        "        filtered_sentences.append(sentence)\n",
        "\n",
        "\n",
        "for sentence in filtered_sentences:\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q5IwGzzA7LE",
        "outputId": "5639a5b1-2f14-4fc4-c60d-d91a1ef2a34b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.30.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence_transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.6.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=195c4fb1534973b53ef657b57f6459a28ad4e73cc3c0954e3de4ccd0bd400f87\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: sentencepiece, sentence_transformers\n",
            "Successfully installed sentence_transformers-2.2.2 sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
        "model = AutoModel.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "1ffa1607e6144f498f8499a7ab0779e5",
            "4b9daa269e5f4b5eabe882dbeeedd657",
            "fe4004c6cca445e38770044410867ab1",
            "33bbbdc9cb9e45789f375e6569bad2bc",
            "fbbfaa428fa245368158f0c59448178d",
            "7b8510490ecb41ba9ea0283e18c90cca",
            "aaca3dc7291e4a19b30c911da2941830",
            "843c63626fe24e8c8790a47335a9af0d",
            "4bb7fb952300404f82639adfb2e6a16f",
            "8c261d17bb474c26ac77b9d1a6846834",
            "67210958e5dd4f7cac46bb10ebf646a6",
            "87344ab44ed64279bd364da64ca8b432",
            "52a2a8cf98f947acbbcf3742d32eb8a6",
            "968d0cd48aba4694baadbd48c6155680",
            "ff2a059a852c4948a09e9e668f3dbbbf",
            "c3852507790d46b9962f90748f7b8d66",
            "fcd3314592e3464aab1ad956e859b921",
            "3566b51c17514015a9384c1752d19d12",
            "c50fa130948f48c5b941f321dcb31e30",
            "00eb31fca57541298224d0a2fbeeb191",
            "ffd5c24776d940fdbf25c27b11f3e0a3",
            "37b48799bd1b4655a49ed40cc47204d4",
            "ca35bbadafcd45cfab4ff6753fa35c6f",
            "fe1f09163e41493dabaa40bc946c03d1",
            "82c11f6a5aac41f9be8b2a45b6b17f63",
            "4c60271f80294bf2b1e7e6f25f490c4a",
            "bd594f56528940f8bc8ff3720e42dd8a",
            "1abdb760c49c4ab892004104bec87b82",
            "796ed41209c74fd785c5b10037782751",
            "8d5dab61926246e0a0782407f678c43a",
            "a373e7f21deb466a88c75d3533502b5f",
            "990bd7d2e40646389559494eb418f73f",
            "14a2c3b19934441288f7be2b179d1edd"
          ]
        },
        "id": "TU2MWkS6IvHw",
        "outputId": "b9778b7c-13a4-4593-cc35-1af7d20e6ad8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/434 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ffa1607e6144f498f8499a7ab0779e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.22M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87344ab44ed64279bd364da64ca8b432"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/654M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca35bbadafcd45cfab4ff6753fa35c6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/bert-base-parsbert-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from rdflib import Graph, Namespace\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch"
      ],
      "metadata": {
        "id": "TbWzPs3PIxvU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ParsBERT model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
        "model = AutoModel.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS1EPRvxUP_W",
        "outputId": "92a2445c-1e26-4e25-de6d-0114227afc09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/bert-base-parsbert-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Prepare the question\n",
        "#question = \"معاونت آموزشی انتصاب میشود دانشکده به چه کسی ؟\"\n",
        "question = \"آخرین مدرک اخذ شده دکتر شمسفرد چه است\"\n",
        "#question = \"تعداد واحد مورد نیاز برای فارغ التحصیلی چند تاست\"\n",
        "#question = \"درس هوش مصنوعی در 1402 کجا برگزار میشود؟\"\n",
        "question = \"معدل مشروطی در ارشد چند است؟\"\n",
        "question = \"دفتر دکتر قوامی زاده کدام طبقه است؟\"\n",
        "question = \"حوزه تحقیق دکتر شمس فرد چیست؟\"\n",
        "question = \"دفتر دکتر شمس فرد کدام طبقه است؟\"\n",
        "question = \"ساعت حضور دکتر قوامی زاده چه موقع است؟\"\n",
        "question = \"حداقل واحد برای ثبت نام ارشد را بگو\"\n",
        "question = \"کتاب راسل در کجا موجود است؟\"\n",
        "question = \" دکتر شمسفرد در کجا کار میکند\"\n",
        "question = \"منبع درس هوش راسل \"\n",
        "question = \"گروه آموزشی دکتر سلیمی بدر چیست؟\"\n",
        "question = \"آدرس مکان دفتر دکتر شمس فرد کجاست؟\"\n",
        "question = \"در ارشد چند ترم میتوان مرخصی گرفت؟\"\n",
        "question = \"شماره تلفن دکتر شمس فرد چیست؟\"\n",
        "question = \"دکتر شمس فرد از کجا فارغ التحصیلی ؟\"\n",
        "question = \"آموزش محور یعنی چه\"\n",
        "\n",
        "\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "similarity_scores = cosine_similarity(question_embedding, sentence_embeddings)\n",
        "\n",
        "\n",
        "best_index = similarity_scores.argmax()\n",
        "best_sentence = filtered_sentences[best_index]\n",
        "\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", best_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOMD1mR-Tkq2",
        "outputId": "ce002d2f-3485-4007-9a70-673614af06cd"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: آموزش محور یعنی چه\n",
            "Answer: قانون آموزش محور برای ارشد وضع میشود برای دانشگاه شهیدبهشتی.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "paraphrased_questions = [\n",
        "\"مقدار مبلغ شهریه ثابت در مقطع ارشد چند ریال است؟\",\n",
        "\"مبلغ ثابت شهریه در دوره ارشد چقدر است؟\",\n",
        "\"مبلغ شهریه ثابت در مقطع ارشد چند ریال است؟\",\n",
        "\"چند ریال برای مبلغ شهریه ثابت در دوره ارشد تعیین شده است؟\",\n",
        "\"مقدار مبلغ شهریه ثابت در مقطع ارشد چقدر می‌باشد؟\",\n",
        "\"چه مبلغی برای شهریه ثابت در مقطع ارشد تعیین شده است؟\",\n",
        "\"مبلغ ثابت شهریه در مقطع ارشد چه مقداری است؟\",\n",
        "\"مبلغ شهریه ثابت در دوره ارشد چقدر می‌باشد؟\",\n",
        "\"چه مبلغی برای مبلغ شهریه ثابت در مقطع ارشد تعیین شده است؟\",\n",
        "\"مقدار مبلغ شهریه ثابت در دوره ارشد چند ریال می باشد؟\"\n",
        "]\n",
        "reference_answer =\"قانون شهریه ثابت ارشد مبلغ شهریه 59000000 ریال.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1JMxviy6vsR",
        "outputId": "5590f435-386f-4d5b-a0a5-cd0a5cc37044"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "مقدار مبلغ شهریه ثابت در مقطع ارشد چند ریال است؟\n",
            "مبلغ ثابت شهریه در دوره ارشد چقدر است؟\n",
            "مبلغ شهریه ثابت در مقطع ارشد چند ریال است؟\n",
            "چند ریال برای مبلغ شهریه ثابت در دوره ارشد تعیین شده است؟\n",
            "مقدار مبلغ شهریه ثابت در مقطع ارشد چقدر می‌باشد؟\n",
            "چه مبلغی برای شهریه ثابت در مقطع ارشد تعیین شده است؟\n",
            "مبلغ ثابت شهریه در مقطع ارشد چه مقداری است؟\n",
            "مبلغ شهریه ثابت در دوره ارشد چقدر می‌باشد؟\n",
            "چه مبلغی برای مبلغ شهریه ثابت در مقطع ارشد تعیین شده است؟\n",
            "مقدار مبلغ شهریه ثابت در دوره ارشد چند ریال می باشد؟\n",
            "Top-1 Accuracy: 50.00%\n",
            "Top-3 Accuracy: 100.00%\n",
            "Top-5 Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "paraphrased_questions = [\n",
        "\"برای اخذ در مقطع ارشد حداکثر چند واحد مجاز است؟\",\n",
        "\"حداکثر چند واحد برای اخذ در مقطع ارشد مجاز است؟\",\n",
        "\"تعداد واحد مجاز برای اخذ در مقطع ارشد حداکثر چند است؟\",\n",
        "\"حداکثر واحد مجاز برای اخذ در مقطع ارشد چیست؟\",\n",
        "\"حداکثر تعداد واحد برای اخذ در مقطع ارشد چند تاست؟\",\n",
        "\"برای اخذ در مقطع ارشد حداکثر چند تا واحد مجاز است؟\",\n",
        "\"تعداد واحد مجاز برای اخذ در مقطع ارشد حداکثر چند تاست؟\",\n",
        "\"حداکثر چه تعداد واحد برای اخذ در مقطع ارشد مجاز است؟\",\n",
        "\"حداکثر چند تا واحد برای اخذ در مقطع ارشد مجاز است؟\",\n",
        "\"تعداد واحد مجاز برای اخذ در مقطع ارشد حداکثر چند تاست؟\"\n",
        "]\n",
        "reference_answer = \"قانون ثبت نام ارشد حداکثر واحد 14.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trmbDScW4Hpt",
        "outputId": "7b049a2b-c486-417f-bbb5-0a9ccd6e4925"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "برای اخذ در مقطع ارشد حداکثر چند واحد مجاز است؟\n",
            "حداکثر چند واحد برای اخذ در مقطع ارشد مجاز است؟\n",
            "تعداد واحد مجاز برای اخذ در مقطع ارشد حداکثر چند است؟\n",
            "حداکثر واحد مجاز برای اخذ در مقطع ارشد چیست؟\n",
            "حداکثر تعداد واحد برای اخذ در مقطع ارشد چند تاست؟\n",
            "برای اخذ در مقطع ارشد حداکثر چند تا واحد مجاز است؟\n",
            "تعداد واحد مجاز برای اخذ در مقطع ارشد حداکثر چند تاست؟\n",
            "حداکثر چه تعداد واحد برای اخذ در مقطع ارشد مجاز است؟\n",
            "حداکثر چند تا واحد برای اخذ در مقطع ارشد مجاز است؟\n",
            "تعداد واحد مجاز برای اخذ در مقطع ارشد حداکثر چند تاست؟\n",
            "Top-1 Accuracy: 80.00%\n",
            "Top-3 Accuracy: 100.00%\n",
            "Top-5 Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paraphrased_questions = [\n",
        "\"ساعت حضور دکتر شمس فرد چه موقع است؟\",\n",
        "\"دکتر شمس فرد در چه ساعاتی حاضر است؟\",\n",
        "\"ساعت حضور دکتر شمس فرد در چه زمانی است؟\",\n",
        "\"چه ساعت‌هایی دکتر شمس فرد حاضر است؟\",\n",
        "\"ساعت حضور دکتر شمس فرد در کدام بازه زمانی است؟\",\n",
        "\"دکتر شمس فرد در چه بازه‌های زمانی حاضر است؟\",\n",
        "\"چه زمانی برای ساعت حضور دکتر شمس فرد مشخص شده است؟\",\n",
        "\"دکتر شمس فرد در کدام ساعات حاضر است؟\",\n",
        "\"ساعت حضور دکتر شمس فرد در چه بازه‌های زمانی است؟\",\n",
        "\"چه ساعاتی دکتر شمس فرد حاضر است؟\"\n",
        "]\n",
        "reference_answer = \"دفتر دکتر شمس فرد ساعت حضور شنبه‌ها از ساعت  ده تا دوازده، چهارشنبه‌ها از ساعت سه تا پنج.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPW-j9pdydqH",
        "outputId": "4f5ea16b-a9ea-4aba-c436-2f56df0e4742"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ساعت حضور دکتر شمس فرد چه موقع است؟\n",
            "دکتر شمس فرد در چه ساعاتی حاضر است؟\n",
            "ساعت حضور دکتر شمس فرد در چه زمانی است؟\n",
            "چه ساعت‌هایی دکتر شمس فرد حاضر است؟\n",
            "ساعت حضور دکتر شمس فرد در کدام بازه زمانی است؟\n",
            "دکتر شمس فرد در چه بازه‌های زمانی حاضر است؟\n",
            "چه زمانی برای ساعت حضور دکتر شمس فرد مشخص شده است؟\n",
            "دکتر شمس فرد در کدام ساعات حاضر است؟\n",
            "ساعت حضور دکتر شمس فرد در چه بازه‌های زمانی است؟\n",
            "چه ساعاتی دکتر شمس فرد حاضر است؟\n",
            "Top-1 Accuracy: 0.00%\n",
            "Top-3 Accuracy: 10.00%\n",
            "Top-5 Accuracy: 10.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paraphrased_questions = [\n",
        "\"آموزش محور یعنی چه؟\",\n",
        "\"معنای آموزش محور چیست؟\",\n",
        "\"مفهوم آموزش محور چیست؟\",\n",
        "\"به چه معناست آموزش محور؟\",\n",
        "\"آموزش محور به چه معنا است؟\",\n",
        "\"چه تعبیری برای آموزش محور وجود دارد؟\",\n",
        "\"چه مفهومی به آموزش محور نسبت داده می‌شود؟\",\n",
        "\"آموزش محور به چه صورتی تعبیر می‌شود؟\",\n",
        "\"به چه شکلی آموزش محور تعبیر می‌شود؟\",\n",
        "\"معنای آموزش محور را توضیح دهید.\"\n",
        "]\n",
        "reference_answer = \"قانون آموزش محور برای ارشد تعریف آموزش محور اگر تا آخر ترم سه، هجده واحد گذرانده نشود، دانشجوی کارشناسی  ارشد، آموزش محور میشود.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHT-q58HxepU",
        "outputId": "f373de2d-6593-4ed1-a22f-21c188c7576a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "آموزش محور یعنی چه؟\n",
            "معنای آموزش محور چیست؟\n",
            "مفهوم آموزش محور چیست؟\n",
            "به چه معناست آموزش محور؟\n",
            "آموزش محور به چه معنا است؟\n",
            "چه تعبیری برای آموزش محور وجود دارد؟\n",
            "چه مفهومی به آموزش محور نسبت داده می‌شود؟\n",
            "آموزش محور به چه صورتی تعبیر می‌شود؟\n",
            "به چه شکلی آموزش محور تعبیر می‌شود؟\n",
            "معنای آموزش محور را توضیح دهید.\n",
            "Top-1 Accuracy: 30.00%\n",
            "Top-3 Accuracy: 100.00%\n",
            "Top-5 Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paraphrased_questions = [\n",
        "\"دکتر شمس فرد از کجا فارغ التحصیل شده است؟\",\n",
        "\"از کدام دانشگاه دکتر شمس فرد فارغ التحصیل شده است؟\",\n",
        "\"دکتر شمس فرد در کدام مرکز تحصیلی فارغ التحصیل شده است؟\",\n",
        "\"دکتر شمس فرد از چه موسسه‌ای فارغ التحصیل شده است؟\",\n",
        "\"محل فارغ التحصیلی دکتر شمس فرد کجاست؟\",\n",
        "\"از کدام موسسه تحصیلی دکتر شمس فرد فارغ التحصیل شده است؟\",\n",
        "\"دکتر شمس فرد در کدام دانشگاه فارغ التحصیل شده است؟\",\n",
        "\"محل فارغ التحصیل شدن دکتر شمس فرد کجا بوده است\",\n",
        "\"دکتر شمس فرد از کجا فارغ التحصیل شده است؟\",\n",
        "\"از کدام مرکز تحصیلی دکتر شمس فرد فارغ التحصیل شده است؟\"\n",
        "]\n",
        "reference_answer = \"دکتر شمس فرد محل فارغ التحصیلی دانشگاه صنعتی امیرکبیر.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7ti-MLav66u",
        "outputId": "0331377a-9770-44d3-dd16-7227a81909b1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "دکتر شمس فرد از کجا فارغ التحصیل شده است؟\n",
            "از کدام دانشگاه دکتر شمس فرد فارغ التحصیل شده است؟\n",
            "دکتر شمس فرد در کدام مرکز تحصیلی فارغ التحصیل شده است؟\n",
            "دکتر شمس فرد از چه موسسه‌ای فارغ التحصیل شده است؟\n",
            "محل فارغ التحصیلی دکتر شمس فرد کجاست؟\n",
            "از کدام موسسه تحصیلی دکتر شمس فرد فارغ التحصیل شده است؟\n",
            "دکتر شمس فرد در کدام دانشگاه فارغ التحصیل شده است؟\n",
            "محل فارغ التحصیل شدن دکتر شمس فرد کجا بوده است\n",
            "دکتر شمس فرد از کجا فارغ التحصیل شده است؟\n",
            "از کدام مرکز تحصیلی دکتر شمس فرد فارغ التحصیل شده است؟\n",
            "Top-1 Accuracy: 50.00%\n",
            "Top-3 Accuracy: 90.00%\n",
            "Top-5 Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paraphrased_questions = [\n",
        "\"شماره تلفن دکتر شمس فرد چیست؟\",\n",
        "\"دکتر شمس فرد چه شماره تلفنی دارد؟\",\n",
        "\"شماره تماس دکتر شمس فرد چیست؟\",\n",
        "\"دکتر شمس فرد چه شماره تلفنی را دارد؟\",\n",
        "\"شماره تلفن دکتر شمس فرد به چه صورتی است؟\",\n",
        "\"دکتر شمس فرد چه شماره تماسی را دارد؟\",\n",
        "\"شماره تماس دکتر شمس فرد چگونه است؟\",\n",
        "\"دکتر شمس فرد چه شماره تلفنی دارد؟\",\n",
        "\"راه ارتباطی تلفنی با دکتر شمس فرد چیست؟\",\n",
        "\"دکتر شمس فرد چه شماره تماسی را در اختیار دارد؟\"\n",
        "]\n",
        "reference_answer = \"دکتر شمس فرد شماره تلفن 29904171.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4Ksk7d-vhae",
        "outputId": "0d17db9b-18cf-45c0-fdce-6a42ed209dc7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "شماره تلفن دکتر شمس فرد چیست؟\n",
            "دکتر شمس فرد چه شماره تلفنی دارد؟\n",
            "شماره تماس دکتر شمس فرد چیست؟\n",
            "دکتر شمس فرد چه شماره تلفنی را دارد؟\n",
            "شماره تلفن دکتر شمس فرد به چه صورتی است؟\n",
            "دکتر شمس فرد چه شماره تماسی را دارد؟\n",
            "شماره تماس دکتر شمس فرد چگونه است؟\n",
            "دکتر شمس فرد چه شماره تلفنی دارد؟\n",
            "راه ارتباطی تلفنی با دکتر شمس فرد چیست؟\n",
            "دکتر شمس فرد چه شماره تماسی را در اختیار دارد؟\n",
            "Top-1 Accuracy: 80.00%\n",
            "Top-3 Accuracy: 90.00%\n",
            "Top-5 Accuracy: 90.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paraphrased_questions = [\n",
        "\"در ارشد چند ترم می‌توان مرخصی گرفت؟\",\n",
        "\"تعداد ترم‌های مجاز برای مرخصی در دوره ارشد چند است؟\",\n",
        "\"در دوره ارشد چه تعداد ترم مرخصی قابل استفاده است؟\",\n",
        "\"در ارشد به چه تعداد ترم مرخصی اجازه داده می‌شود؟\",\n",
        "\"تعداد ترم‌های قابل استفاده برای مرخصی در دوره ارشد چه مقداری است؟\",\n",
        "\"در دوره ارشد چند ترم مرخصی قابل استفاده است؟\",\n",
        "\"چه تعداد ترم برای مرخصی در دوره ارشد مجاز است؟\",\n",
        "\"در دوره ارشد به چه تعداد ترم مرخصی اجازه داده می‌شود؟\",\n",
        "\"تعداد ترم‌های مجاز برای مرخصی در ارشد چند است؟\",\n",
        "\"در ارشد چند ترم مرخصی قابل استفاده است؟\"\n",
        "]\n",
        "reference_answer = \"قانون مرخصی گرفتن ارشد تعداد ترم 1.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N4MWEgWvJA6",
        "outputId": "19f3a254-5e65-4479-e703-8858ee024edd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "در ارشد چند ترم می‌توان مرخصی گرفت؟\n",
            "تعداد ترم‌های مجاز برای مرخصی در دوره ارشد چند است؟\n",
            "در دوره ارشد چه تعداد ترم مرخصی قابل استفاده است؟\n",
            "در ارشد به چه تعداد ترم مرخصی اجازه داده می‌شود؟\n",
            "تعداد ترم‌های قابل استفاده برای مرخصی در دوره ارشد چه مقداری است؟\n",
            "در دوره ارشد چند ترم مرخصی قابل استفاده است؟\n",
            "چه تعداد ترم برای مرخصی در دوره ارشد مجاز است؟\n",
            "در دوره ارشد به چه تعداد ترم مرخصی اجازه داده می‌شود؟\n",
            "تعداد ترم‌های مجاز برای مرخصی در ارشد چند است؟\n",
            "در ارشد چند ترم مرخصی قابل استفاده است؟\n",
            "Top-1 Accuracy: 100.00%\n",
            "Top-3 Accuracy: 100.00%\n",
            "Top-5 Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paraphrased_questions = [\n",
        "\"آدرس مکان دفتر دکتر شمس فرد کجاست؟\",\n",
        "\"مکان دفتر دکتر شمس فرد آدرسش؟\",\n",
        "\"دفتر دکتر شمس فرد در کدام مکان قرار دارد؟\",\n",
        "\"آدرس دفتر دکتر شمس فرد کجاست؟\",\n",
        "\"دفتر دکتر شمس فرد در چه آدرسی قرار دارد؟\",\n",
        "\"دفتر دکتر شمس فرد در کدام آدرس است؟\",\n",
        "\"دفتر دکتر شمس فرد در کدام مکان قرار گرفته است؟\",\n",
        "\"آدرس مکان دفتر دکتر شمس فرد کجاست؟\",\n",
        "\"دفتر دکتر شمس فرد در کدام نقطه قرار گرفته است؟\",\n",
        "\"آدرس محل دفتر دکتر شمس فرد کجا است؟\"\n",
        "]\n",
        "reference_answer = \"دفتر دکتر شمس فرد آدرس مکان ولنجک - دانشگاه بهشتی- دانشکده کامپیوتر.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18f3RJJ5usOz",
        "outputId": "6ae33b4b-dcde-48f6-bc6a-4f71e9df953c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "آدرس مکان دفتر دکتر شمس فرد کجاست؟\n",
            "مکان دفتر دکتر شمس فرد آدرسش؟\n",
            "دفتر دکتر شمس فرد در کدام مکان قرار دارد؟\n",
            "آدرس دفتر دکتر شمس فرد کجاست؟\n",
            "دفتر دکتر شمس فرد در چه آدرسی قرار دارد؟\n",
            "دفتر دکتر شمس فرد در کدام آدرس است؟\n",
            "دفتر دکتر شمس فرد در کدام مکان قرار گرفته است؟\n",
            "آدرس مکان دفتر دکتر شمس فرد کجاست؟\n",
            "دفتر دکتر شمس فرد در کدام نقطه قرار گرفته است؟\n",
            "آدرس محل دفتر دکتر شمس فرد کجا است؟\n",
            "Top-1 Accuracy: 40.00%\n",
            "Top-3 Accuracy: 50.00%\n",
            "Top-5 Accuracy: 70.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paraphrased_questions = [\n",
        "\"گروه آموزشی دکتر سلیمی بدر چیست؟\",\n",
        "\"به چه گروه آموزشی دکتر سلیمی بدر اختصاص داده شده است؟\",\n",
        "\"در چه گروه آموزشی دکتر سلیمی کار میکند؟\",\n",
        "\"دکتر سلیمی بدر در کدام گروه آموزشی فعالیت می‌کند؟\",\n",
        "\"گروه آموزشی مرتبط با دکتر سلیمی بدر چه است؟\",\n",
        "\"به کدام گروه آموزشی دکتر سلیمی بدر تعلق دارد؟\",\n",
        "\"دکتر سلیمی بدر در کدام گروه آموزشی فعالیت می‌کند؟\",\n",
        "\"گروه آموزشی که دکتر سلیمی بدر در آن فعالیت می‌کند، چه است؟\",\n",
        "\"در چه گروه آموزشی دکتر سلیمی بدر تخصص دارد؟\",\n",
        "\"به چه گروه آموزشی دکتر سلیمی بدر تعلق دارد؟\"\n",
        "]\n",
        "reference_answer = \"دکتر سلیمی بدر گروه آموزشی شخص هوش مصنوعی.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meM3KcO8td_V",
        "outputId": "05adedef-9652-4bc1-d694-670d1a6c1fca"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "گروه آموزشی دکتر سلیمی بدر چیست؟\n",
            "به چه گروه آموزشی دکتر سلیمی بدر اختصاص داده شده است؟\n",
            "در چه گروه آموزشی دکتر سلیمی کار میکند؟\n",
            "دکتر سلیمی بدر در کدام گروه آموزشی فعالیت می‌کند؟\n",
            "گروه آموزشی مرتبط با دکتر سلیمی بدر چه است؟\n",
            "به کدام گروه آموزشی دکتر سلیمی بدر تعلق دارد؟\n",
            "دکتر سلیمی بدر در کدام گروه آموزشی فعالیت می‌کند؟\n",
            "گروه آموزشی که دکتر سلیمی بدر در آن فعالیت می‌کند، چه است؟\n",
            "در چه گروه آموزشی دکتر سلیمی بدر تخصص دارد؟\n",
            "به چه گروه آموزشی دکتر سلیمی بدر تعلق دارد؟\n",
            "Top-1 Accuracy: 20.00%\n",
            "Top-3 Accuracy: 60.00%\n",
            "Top-5 Accuracy: 60.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paraphrased_questions = [\n",
        "\"منبع درس هوش مصنوعی چیست؟\",\n",
        "\"برای درس هوش مصنوعی،  چه منبعی موجود است؟\",\n",
        "\"منبع مورد استفاده برای درس هوش مصنوعی چیست؟\",\n",
        "\"منبعی که برای درس هوش مصنوعی مورد استفاده قرار می‌گیرد چیست؟\",\n",
        "\"چه منبعی برای درس هوش مصنوعی تعیین شده است؟\",\n",
        "\"درس هوش مصنوعی از چه منابعی پشتیبانی می‌شود؟\",\n",
        "\"منبع درس هوش مصنوعی به چه صورتی تعیین شده است؟\",\n",
        "\"چه منابعی برای درس هوش مصنوعی در نظر گرفته شده است؟\",\n",
        "\"منبع درس هوش مصنوعی به چه شکلی تعیین شده است؟\",\n",
        "\"برای درس هوش مصنوعی، چه منابعی مورد استفاده قرار می‌گیرند؟\"\n",
        "]\n",
        "reference_answer = \"کتاب راسل منبع است برای درس هوش مصنوعی در ترم دوم سال 1401.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Zm6Z-wrs7xp",
        "outputId": "1c2fbbc5-0773-49fa-d85d-c33ecff847ae"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "منبع درس هوش مصنوعی چیست؟\n",
            "برای درس هوش مصنوعی،  چه منبعی موجود است؟\n",
            "منبع مورد استفاده برای درس هوش مصنوعی چیست؟\n",
            "منبعی که برای درس هوش مصنوعی مورد استفاده قرار می‌گیرد چیست؟\n",
            "چه منبعی برای درس هوش مصنوعی تعیین شده است؟\n",
            "درس هوش مصنوعی از چه منابعی پشتیبانی می‌شود؟\n",
            "منبع درس هوش مصنوعی به چه صورتی تعیین شده است؟\n",
            "چه منابعی برای درس هوش مصنوعی در نظر گرفته شده است؟\n",
            "منبع درس هوش مصنوعی به چه شکلی تعیین شده است؟\n",
            "برای درس هوش مصنوعی، چه منابعی مورد استفاده قرار می‌گیرند؟\n",
            "Top-1 Accuracy: 20.00%\n",
            "Top-3 Accuracy: 40.00%\n",
            "Top-5 Accuracy: 90.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paraphrased_questions = [\n",
        "\"دکتر شمسفرد در کجا کار می‌کند؟\",\n",
        "\"دکتر شمسفرد در چه محلی مشغول به کار است؟\",\n",
        "\"در کدام مکان دکتر شمسفرد فعالیت می‌کند؟\",\n",
        "\"کجا برای دکتر شمسفرد محل کار تعیین شده است؟\",\n",
        "\"مکان کار دکتر شمسفرد کجاست؟\",\n",
        "\"در کجا دکتر شمسفرد مشغول به کار است؟\",\n",
        "\"دکتر شمسفرد در کدام مرکز کار می‌کند؟\",\n",
        "\"در کدام محل، دکتر شمسفرد به کار می‌پردازد؟\",\n",
        "\"دکتر شمسفرد در کجا به کار می‌پردازد؟\",\n",
        "\"کجا برای دکتر شمسفرد به عنوان محل فعالیت تعیین شده است؟\"\n",
        "]\n",
        "reference_answer = \"دکتر شمس فرد کار میکند در دانشگاه شهیدبهشتی.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN455kbKsp-R",
        "outputId": "020f680d-5fdb-4c9f-827b-ca6ae706510d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "دکتر شمسفرد در کجا کار می‌کند؟\n",
            "دکتر شمسفرد در چه محلی مشغول به کار است؟\n",
            "در کدام مکان دکتر شمسفرد فعالیت می‌کند؟\n",
            "کجا برای دکتر شمسفرد محل کار تعیین شده است؟\n",
            "مکان کار دکتر شمسفرد کجاست؟\n",
            "در کجا دکتر شمسفرد مشغول به کار است؟\n",
            "دکتر شمسفرد در کدام مرکز کار می‌کند؟\n",
            "در کدام محل، دکتر شمسفرد به کار می‌پردازد؟\n",
            "دکتر شمسفرد در کجا به کار می‌پردازد؟\n",
            "کجا برای دکتر شمسفرد به عنوان محل فعالیت تعیین شده است؟\n",
            "Top-1 Accuracy: 70.00%\n",
            "Top-3 Accuracy: 80.00%\n",
            "Top-5 Accuracy: 80.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paraphrased_questions = [\n",
        "\"کتاب راسل در کجا موجود است؟\",\n",
        "\"کجا می‌توان کتاب راسل را یافت؟\",\n",
        "\"کتاب راسل در چه مکانی قابل دسترسی است؟\",\n",
        "\"در کدام مکان می‌توان کتاب راسل را پیدا کرد؟\",\n",
        "\"کتاب راسل در کدام محل قرار دارد؟\",\n",
        "\"کجا می‌توان کتاب راسل را پیدا کرد؟\",\n",
        "\"کتاب راسل در کدام مرکز موجود است؟\",\n",
        "\"در کدام مکان می‌توان کتاب راسل را یافت؟\",\n",
        "\"کتاب راسل در کجا قرار گرفته است؟\",\n",
        "\"کجا می‌توان کتاب راسل را دریافت کرد؟\"\n",
        "]\n",
        "reference_answer = \"کتاب راسل موجود است در کتابخانه مرکزی دانشکده بهشتی.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY9ytlq2rbkR",
        "outputId": "14c68ff8-b225-4296-c6f6-3f682d722d3c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "کتاب راسل در کجا موجود است؟\n",
            "کجا می‌توان کتاب راسل را یافت؟\n",
            "کتاب راسل در چه مکانی قابل دسترسی است؟\n",
            "در کدام مکان می‌توان کتاب راسل را پیدا کرد؟\n",
            "کتاب راسل در کدام محل قرار دارد؟\n",
            "کجا می‌توان کتاب راسل را پیدا کرد؟\n",
            "کتاب راسل در کدام مرکز موجود است؟\n",
            "در کدام مکان می‌توان کتاب راسل را یافت؟\n",
            "کتاب راسل در کجا قرار گرفته است؟\n",
            "کجا می‌توان کتاب راسل را دریافت کرد؟\n",
            "Top-1 Accuracy: 0.00%\n",
            "Top-3 Accuracy: 80.00%\n",
            "Top-5 Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paraphrased_questions = [\n",
        "\"حداقل واحد مورد نیاز برای ثبت نام در دوره ارشد چقدر است؟\",\n",
        "\"چند واحد حداقل برای ثبت نام در دوره ارشد مورد نیاز است؟\",\n",
        "\"حداقل تعداد واحد مورد نیاز برای ثبت نام در دوره ارشد چیست؟\",\n",
        "\"چه تعداد واحد حداقل برای ثبت نام در دوره ارشد الزامی است؟\",\n",
        "\"برای ثبت نام در دوره ارشد، حداقل چند واحد لازم است؟\",\n",
        "\"حداقل تعداد واحد برای ثبت نام در دوره ارشد چه است؟\",\n",
        "\"اخذ حداقل چند واحد برای ثبت نام در دوره ارشد لازم است؟\",\n",
        "\"حداقل واحد مورد نیاز برای ثبت نام در دوره ارشد چقدر می‌باشد؟\",\n",
        "\"چه تعداد واحد حداقل برای ثبت نام در دوره ارشد لازم است؟\",\n",
        "\"برای ثبت نام در دوره ارشد، حداقل چند واحد الزامی است؟\"\n",
        "]\n",
        "reference_answer = \"قانون ثبت نام ارشد حداقل واحد 8.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON8XAn4Rq9Pf",
        "outputId": "d139e238-318a-4402-de2a-fdf40d46429f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "حداقل واحد مورد نیاز برای ثبت نام در دوره ارشد چقدر است؟\n",
            "چند واحد حداقل برای ثبت نام در دوره ارشد مورد نیاز است؟\n",
            "حداقل تعداد واحد مورد نیاز برای ثبت نام در دوره ارشد چیست؟\n",
            "چه تعداد واحد حداقل برای ثبت نام در دوره ارشد الزامی است؟\n",
            "برای ثبت نام در دوره ارشد، حداقل چند واحد لازم است؟\n",
            "حداقل تعداد واحد برای ثبت نام در دوره ارشد چه است؟\n",
            "اخذ حداقل چند واحد برای ثبت نام در دوره ارشد لازم است؟\n",
            "حداقل واحد مورد نیاز برای ثبت نام در دوره ارشد چقدر می‌باشد؟\n",
            "چه تعداد واحد حداقل برای ثبت نام در دوره ارشد لازم است؟\n",
            "برای ثبت نام در دوره ارشد، حداقل چند واحد الزامی است؟\n",
            "Top-1 Accuracy: 100.00%\n",
            "Top-3 Accuracy: 100.00%\n",
            "Top-5 Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paraphrased_questions = [\n",
        "\"ساعت حضور دکتر قوامی زاده چه موقع است؟\",\n",
        "\"دکتر قوامی زاده در چه ساعاتی حاضر است؟\",\n",
        "\"ساعت حضور دکتر قوامی زاده در چه زمانی است؟\",\n",
        "\"چه ساعت‌هایی دکتر قوامی زاده حاضر است؟\",\n",
        "\"ساعت حضور دکتر قوامی زاده در کدام بازه زمانی است؟\",\n",
        "\"دکتر قوامی زاده در چه بازه‌های زمانی حاضر است؟\",\n",
        "\"چه زمانی برای ساعت حضور دکتر قوامی زاده مشخص شده است؟\",\n",
        "\"دکتر قوامی زاده در کدام ساعات حاضر است؟\",\n",
        "\"ساعت حضور دکتر قوامی زاده در چه بازه‌های زمانی است؟\",\n",
        "\"چه ساعاتی دکتر قوامی زاده حاضر است؟\"\n",
        "]\n",
        "reference_answer = \"دفتر دکتر قوامی زاده ساعت حضور شنبه تا سه شنبه ساعت هشت تا نه.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HguDxZCqoR3",
        "outputId": "4df535fb-7ba9-4406-ff52-caba01acd2f7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ساعت حضور دکتر قوامی زاده چه موقع است؟\n",
            "دکتر قوامی زاده در چه ساعاتی حاضر است؟\n",
            "ساعت حضور دکتر قوامی زاده در چه زمانی است؟\n",
            "چه ساعت‌هایی دکتر قوامی زاده حاضر است؟\n",
            "ساعت حضور دکتر قوامی زاده در کدام بازه زمانی است؟\n",
            "دکتر قوامی زاده در چه بازه‌های زمانی حاضر است؟\n",
            "چه زمانی برای ساعت حضور دکتر قوامی زاده مشخص شده است؟\n",
            "دکتر قوامی زاده در کدام ساعات حاضر است؟\n",
            "ساعت حضور دکتر قوامی زاده در چه بازه‌های زمانی است؟\n",
            "چه ساعاتی دکتر قوامی زاده حاضر است؟\n",
            "Top-1 Accuracy: 50.00%\n",
            "Top-3 Accuracy: 50.00%\n",
            "Top-5 Accuracy: 60.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "paraphrased_questions = [\n",
        "\"دفتر دکتر شمس فرد کدام طبقه است؟\",\n",
        "\"دفتر دکتر شمس فرد در کدام طبقه قرار دارد؟\",\n",
        "\"در کدام طبقه دفتر دکتر شمس فرد قرار دارد؟\",\n",
        "\"کدام طبقه برای دفتر دکتر شمس فرد انتخاب شده است؟\",\n",
        "\"طبقه‌ای که دفتر دکتر شمس فرد در آن قرار دارد، کدام است؟\",\n",
        "\"دفتر دکتر شمس فرد در کدام طبقه است؟\",\n",
        "\"کدام طبقه مکان دفتر دکتر شمس فرد است؟\",\n",
        "\"دفتر دکتر شمس فرد در کدام طبقه می باشد؟\",\n",
        "\"کدام طبقه محل دفتر دکتر شمس فرد است؟\",\n",
        "\"دفتر دکتر شمس فرد در چه طبقه ای قرار گرفته است؟\"\n",
        "]\n",
        "reference_answer = \"دفتر دکتر شمس فرد طبقه 4.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjB_uXiwp1Wf",
        "outputId": "79db45d8-9c22-49c0-ad16-f89c781c4845"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "دفتر دکتر شمس فرد کدام طبقه است؟\n",
            "دفتر دکتر شمس فرد در کدام طبقه قرار دارد؟\n",
            "در کدام طبقه دفتر دکتر شمس فرد قرار دارد؟\n",
            "کدام طبقه برای دفتر دکتر شمس فرد انتخاب شده است؟\n",
            "طبقه‌ای که دفتر دکتر شمس فرد در آن قرار دارد، کدام است؟\n",
            "دفتر دکتر شمس فرد در کدام طبقه است؟\n",
            "کدام طبقه مکان دفتر دکتر شمس فرد است؟\n",
            "دفتر دکتر شمس فرد در کدام طبقه می باشد؟\n",
            "کدام طبقه محل دفتر دکتر شمس فرد است؟\n",
            "دفتر دکتر شمس فرد در چه طبقه ای قرار گرفته است؟\n",
            "Top-1 Accuracy: 80.00%\n",
            "Top-3 Accuracy: 100.00%\n",
            "Top-5 Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paraphrased_questions = [\n",
        "\"حوزه تحقیق دکتر شمس فرد چیست؟\",\n",
        "\"به چه حوزه تحقیقی دکتر شمس فرد اختصاص داده شده است؟\",\n",
        "\"به چه زمینه تحقیقی دکتر شمس فرد متمرکز است؟\",\n",
        "\"دکتر شمس فرد در کدام حوزه تحقیقی فعالیت می‌کند؟\",\n",
        "\"حوزه تحقیقات دکتر شمس فرد به چه موضوعی مرتبط است؟\",\n",
        "\"به کدام حوزه تحقیقی دکتر شمس فرد متمرکز شده است؟\",\n",
        "\"دکتر شمس فرد در چه زمینه‌ای تحقیق می‌کند؟\",\n",
        "\"حوزه تحقیقاتی که دکتر شمس فرد در آن فعالیت می‌کند، چه است؟\",\n",
        "\"در چه زمینه‌ای دکتر شمس فرد تحقیق می‌کند؟\",\n",
        "\"به چه حوزه تحقیقی دکتر شمس فرد اشتغال دارد؟\"\n",
        "]\n",
        "reference_answer = \"دکتر شمس فرد حوزه تحقیق پردازش زبان طبیعی-هستان شناسی-مهندسی دانش و سیستم های دانش پایه-وب معنایی-هوش مصنوعی.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc1rGKACpVAo",
        "outputId": "acf8981a-f365-4f30-d568-66a3b0741dca"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "حوزه تحقیق دکتر شمس فرد چیست؟\n",
            "به چه حوزه تحقیقی دکتر شمس فرد اختصاص داده شده است؟\n",
            "به چه زمینه تحقیقی دکتر شمس فرد متمرکز است؟\n",
            "دکتر شمس فرد در کدام حوزه تحقیقی فعالیت می‌کند؟\n",
            "حوزه تحقیقات دکتر شمس فرد به چه موضوعی مرتبط است؟\n",
            "به کدام حوزه تحقیقی دکتر شمس فرد متمرکز شده است؟\n",
            "دکتر شمس فرد در چه زمینه‌ای تحقیق می‌کند؟\n",
            "حوزه تحقیقاتی که دکتر شمس فرد در آن فعالیت می‌کند، چه است؟\n",
            "در چه زمینه‌ای دکتر شمس فرد تحقیق می‌کند؟\n",
            "به چه حوزه تحقیقی دکتر شمس فرد اشتغال دارد؟\n",
            "Top-1 Accuracy: 60.00%\n",
            "Top-3 Accuracy: 100.00%\n",
            "Top-5 Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "paraphrased_questions = [\n",
        "\"دفتر دکتر قوامی زاده کدام طبقه است؟\",\n",
        "\"دفتر دکتر قوامی زاده در کدام طبقه قرار دارد؟\",\n",
        "\"در کدام طبقه دفتر دکتر قوامی زاده قرار دارد؟\",\n",
        "\"کدام طبقه به عنوان محل دفتر دکتر قوامی زاده مشخص شده است؟\",\n",
        "\"طبقه‌ای که دفتر دکتر قوامی زده در آن قرار دارد، کدام است؟\",\n",
        "\"دفتر دکتر قوامی زاده در کدام طبقه می باشد؟\",\n",
        "\"کدام طبقه مکان دفتر دکتر قوامی زاده است؟\",\n",
        "\"دفتر دکتر قوامی زاده در کدام طبقه است؟\",\n",
        "\"کدام طبقه برای دفتر دکتر قوامی زاده انتخاب شده است؟\",\n",
        "\"دفتر دکتر قوامی زاده در کدام طبقه قرار گرفته است؟\"\n",
        "]\n",
        "reference_answer = \"دفتر دکتر قوامی زاده طبقه 4.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkxTMqL3od__",
        "outputId": "3265aa55-1e6e-4229-fc11-4ef62ba9a1ff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "دفتر دکتر قوامی زاده کدام طبقه است؟\n",
            "دفتر دکتر قوامی زاده در کدام طبقه قرار دارد؟\n",
            "در کدام طبقه دفتر دکتر قوامی زاده قرار دارد؟\n",
            "کدام طبقه به عنوان محل دفتر دکتر قوامی زاده مشخص شده است؟\n",
            "طبقه‌ای که دفتر دکتر قوامی زده در آن قرار دارد، کدام است؟\n",
            "دفتر دکتر قوامی زاده در کدام طبقه می باشد؟\n",
            "کدام طبقه مکان دفتر دکتر قوامی زاده است؟\n",
            "دفتر دکتر قوامی زاده در کدام طبقه است؟\n",
            "کدام طبقه برای دفتر دکتر قوامی زاده انتخاب شده است؟\n",
            "دفتر دکتر قوامی زاده در کدام طبقه قرار گرفته است؟\n",
            "Top-1 Accuracy: 20.00%\n",
            "Top-3 Accuracy: 90.00%\n",
            "Top-5 Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#question = \"به چه شخصی معاونت آموزشی انتصاب می‌شود؟\"\n",
        "\n",
        "\n",
        "paraphrased_questions = [\n",
        "\"معدل مشروطی در ارشد چند است؟\",\n",
        "\"معدل مشروطی در دوره ارشد چیست؟\",\n",
        "\"معدل مشروطی در دوره ارشد چه مقدار است؟\",\n",
        "\"معدل مشروطی در دوره ارشد چه عددی است؟\",\n",
        "\"معدل مشروطی در دوره ارشد چیست؟\",\n",
        "\"در دوره ارشد، معدل برای مشروط شدن چند است؟\",\n",
        "\"مقدار معدل مشروطی در دوره ارشد چه است؟\",\n",
        "\"چه مقداری برای معدل مشروطی در دوره ارشد لازم است؟\",\n",
        "\"در دوره ارشد، چه معدلی برای مشروطی است؟\",\n",
        "\"معدل مشروطی در دوره ارشد به چه میزانی رسیده است؟\"\n",
        "]\n",
        "reference_answer = \"قانون مشروطی در ارشد معدل مشروطی کمتر از 14.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5ZJbdidneoO",
        "outputId": "4a53c514-324c-4635-b6b0-37659ebc15b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "معدل مشروطی در ارشد چند است؟\n",
            "معدل مشروطی در دوره ارشد چیست؟\n",
            "معدل مشروطی در دوره ارشد چه مقدار است؟\n",
            "معدل مشروطی در دوره ارشد چه عددی است؟\n",
            "معدل مشروطی در دوره ارشد چیست؟\n",
            "در دوره ارشد، معدل برای مشروط شدن چند است؟\n",
            "مقدار معدل مشروطی در دوره ارشد چه است؟\n",
            "چه مقداری برای معدل مشروطی در دوره ارشد لازم است؟\n",
            "در دوره ارشد، چه معدلی برای مشروطی است؟\n",
            "معدل مشروطی در دوره ارشد به چه میزانی رسیده است؟\n",
            "Top-1 Accuracy: 90.00%\n",
            "Top-3 Accuracy: 100.00%\n",
            "Top-5 Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#question = \"به چه شخصی معاونت آموزشی انتصاب می‌شود؟\"\n",
        "\n",
        "\n",
        "paraphrased_questions = [\n",
        "\"درس هوش مصنوعی در سال 1402 کجا برگزار می‌شود؟\",\n",
        "\"در کدام محل درس هوش مصنوعی در سال 1402 ارائه می‌شود؟\",\n",
        "\"کجا برنامه‌ریزی شده است برای برگزاری درس هوش مصنوعی در سال 1402؟\",\n",
        "\"در کدام مکان درس هوش مصنوعی در سال 1402 برگزار خواهد شد؟\",\n",
        "\"درس هوش مصنوعی در سال 1402  کجا ارائه می‌شود؟\",\n",
        "\"محل برگزاری درس هوش مصنوعی در سال 1402 کجا است؟\",\n",
        "\"در سال 1402، درس هوش مصنوعی در کجا برگزار می‌شود؟\",\n",
        "\"درس هوش مصنوعی در سال 1402 در چه محلی برگزار می‌شود؟\",\n",
        "\"کدام مکان برای برگزاری درس هوش مصنوعی در سال 1402 در نظر گرفته شده است؟\",\n",
        "\"در کدام محل، درس هوش مصنوعی در سال 1402 ارائه می‌شود؟\"\n",
        "]\n",
        "reference_answer = \"درس هوش مصنوعی در ترم دوم سال 1402 برگزار میشود در کلاس 104 دانشکده کامپیوتر.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC746WfOmBSX",
        "outputId": "372fb79d-a2bb-4ad2-824b-f2965051d3f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "درس هوش مصنوعی در سال 1402 کجا برگزار می‌شود؟\n",
            "در کدام محل درس هوش مصنوعی در سال 1402 ارائه می‌شود؟\n",
            "کجا برنامه‌ریزی شده است برای برگزاری درس هوش مصنوعی در سال 1402؟\n",
            "در کدام مکان درس هوش مصنوعی در سال 1402 برگزار خواهد شد؟\n",
            "درس هوش مصنوعی در سال 1402  کجا ارائه می‌شود؟\n",
            "محل برگزاری درس هوش مصنوعی در سال 1402 کجا است؟\n",
            "در سال 1402، درس هوش مصنوعی در کجا برگزار می‌شود؟\n",
            "درس هوش مصنوعی در سال 1402 در چه محلی برگزار می‌شود؟\n",
            "کدام مکان برای برگزاری درس هوش مصنوعی در سال 1402 در نظر گرفته شده است؟\n",
            "در کدام محل، درس هوش مصنوعی در سال 1402 ارائه می‌شود؟\n",
            "Top-1 Accuracy: 10.00%\n",
            "Top-3 Accuracy: 30.00%\n",
            "Top-5 Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#question = \"به چه شخصی معاونت آموزشی انتصاب می‌شود؟\"\n",
        "\n",
        "\n",
        "paraphrased_questions = [\n",
        "    \"معاونت آموزشی  دانشکده به چه کسی انتصاب میشود\",\n",
        "    \"به چه شخصی معاونت آموزشی انتصاب می‌شود؟\",\n",
        "    \"معاونت آموزشی در دانشکده کامپیوتر به کدام فردی انتصاب می‌یابد؟\",\n",
        "    \"دکتر قوامی زاده به چه سمتی در دانشکده کامپیوتر منصوب می‌شود؟\",\n",
        "    \"معاونت آموزشی دانشکده کامپیوتر بر عهده کیست؟\",\n",
        "    \"در معاونت آموزشی دانشکده کامپیوتر به چه شخصی مربوط میشود؟\",\n",
        "    \"فردی که به عنوان معاون آموزشی دانشکده تعیین می‌شود، چه کسی است؟\",\n",
        "    \"در دانشکده کامپیوتر، معاونت آموزشی به چه فردی سپرده می‌شود؟\",\n",
        "    \"چه نفری به عنوان معاون آموزشی در دانشکده کامپیوتر به کار می‌گیرند؟\",\n",
        "    \"چه شخصیتی معاون آموزشی دانشکده است؟\"\n",
        "]\n",
        "reference_answer = \"معاونت آموزشی دانشکده کامپیوتر بهشتی منصوب میشود به دکتر قوامی زاده.\"\n",
        "\n",
        "# Assuming you have the following variables defined:\n",
        "# encoded_sentences: Tensor of encoded sentences using a tokenizer\n",
        "# model: The pre-trained model for computing sentence embeddings\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "# Calculate the similarity scores for all paraphrased questions\n",
        "with torch.no_grad():\n",
        "    sentence_embeddings = model(**encoded_sentences).last_hidden_state[:, 0, :]\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0UVi4e0IbQ3",
        "outputId": "90a44ee9-db80-409f-83bb-cae34258a8f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "معاونت آموزشی  دانشکده به چه کسی انتصاب میشود\n",
            "به چه شخصی معاونت آموزشی انتصاب می‌شود؟\n",
            "معاونت آموزشی در دانشکده کامپیوتر به کدام فردی انتصاب می‌یابد؟\n",
            "دکتر قوامی زاده به چه سمتی در دانشکده کامپیوتر منصوب می‌شود؟\n",
            "معاونت آموزشی دانشکده کامپیوتر بر عهده کیست؟\n",
            "در معاونت آموزشی دانشکده کامپیوتر به چه شخصی مربوط میشود؟\n",
            "فردی که به عنوان معاون آموزشی دانشکده تعیین می‌شود، چه کسی است؟\n",
            "در دانشکده کامپیوتر، معاونت آموزشی به چه فردی سپرده می‌شود؟\n",
            "چه نفری به عنوان معاون آموزشی در دانشکده کامپیوتر به کار می‌گیرند؟\n",
            "چه شخصیتی معاون آموزشی دانشکده است؟\n",
            "Top-1 Accuracy: 50.00%\n",
            "Top-3 Accuracy: 70.00%\n",
            "Top-5 Accuracy: 70.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "paraphrased_questions = [\n",
        "    \"برای فارغ التحصیلی، تعداد واحد مورد نیاز چقدر است؟\",\n",
        "    \"تعداد واحد مورد نیاز برای فارغ التحصیلی چند است؟\",\n",
        "    \"چند تا واحد باید برای فارغ التحصیلی گرفت؟\",\n",
        "    \"تعداد واحد مورد نیاز برای فارغ التحصیلی چنده؟\",\n",
        "    \"تعداد واحد مورد نیاز برای فارغ التحصیلی چقدر است؟\",\n",
        "    \"برای فارغ التحصیلی، چند تا واحد باید گرفت؟\",\n",
        "    \"چند واحد لازم است تا فارغ التحصیل شویم؟\",\n",
        "    \"تعداد واحد مورد نیاز برای فارغ التحصیلی چقدر می‌باشد؟\",\n",
        "    \"برای فارغ التحصیلی، تعداد واحد مورد نیاز چقدر است؟\",\n",
        "    \"تعداد واحد مورد نیاز برای فارغ التحصیلی چه مقدار است؟\"\n",
        "]\n",
        "reference_answer = \"قانون فارغ التحصیلی تعداد واحد مورد نیاز برای فارغ التحصیلی 32.\"\n",
        "\n",
        "\n",
        "correct_top1_predictions = 0\n",
        "correct_top3_predictions = 0\n",
        "correct_top5_predictions = 0\n",
        "encoded_sentences = tokenizer(filtered_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "for question in paraphrased_questions:\n",
        "    print(question)\n",
        "    with torch.no_grad():\n",
        "        encoded_question = tokenizer(question, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        question_embedding = model(**encoded_question).last_hidden_state[:, 0, :]\n",
        "\n",
        "    similarity_scores = cosine_similarity(question_embedding.detach().numpy(), sentence_embeddings.detach().numpy())\n",
        "\n",
        "    best_indices = similarity_scores.argsort()[0, ::-1][:5]  # Get the indices of top 5 most similar sentences\n",
        "    best_sentences = [filtered_sentences[i] for i in best_indices]\n",
        "    print(best_sentences[0])\n",
        "    if filtered_sentences[best_indices[0]] == reference_answer:\n",
        "        correct_top1_predictions += 1\n",
        "    if reference_answer in best_sentences[:3]:\n",
        "        correct_top3_predictions += 1\n",
        "    if reference_answer in best_sentences[:5]:\n",
        "        correct_top5_predictions += 1\n",
        "\n",
        "total_questions = len(paraphrased_questions)\n",
        "top1_accuracy = (correct_top1_predictions / total_questions) * 100\n",
        "top3_accuracy = (correct_top3_predictions / total_questions) * 100\n",
        "top5_accuracy = (correct_top5_predictions / total_questions) * 100\n",
        "\n",
        "print(\"Top-1 Accuracy: {:.2f}%\".format(top1_accuracy))\n",
        "print(\"Top-3 Accuracy: {:.2f}%\".format(top3_accuracy))\n",
        "print(\"Top-5 Accuracy: {:.2f}%\".format(top5_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lYZUBzWKUTi",
        "outputId": "22071a43-b99c-4a3d-963d-efce144cf70d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "برای فارغ التحصیلی، تعداد واحد مورد نیاز چقدر است؟\n",
            "قانون فارغ التحصیلی حداقل تعداد دروس اصلی 4.\n",
            "تعداد واحد مورد نیاز برای فارغ التحصیلی چند است؟\n",
            "قانون فارغ التحصیلی حداقل تعداد دروس اصلی 4.\n",
            "چند تا واحد باید برای فارغ التحصیلی گرفت؟\n",
            "قانون فارغ التحصیلی وضع میشود برای دانشگاه شهیدبهشتی.\n",
            "تعداد واحد مورد نیاز برای فارغ التحصیلی چنده؟\n",
            "درس هوش مصنوعی در ترم دوم سال 1401 تعداد واحد درس 3.\n",
            "تعداد واحد مورد نیاز برای فارغ التحصیلی چقدر است؟\n",
            "درس هوش مصنوعی در ترم دوم سال 1401 تعداد واحد درس 3.\n",
            "برای فارغ التحصیلی، چند تا واحد باید گرفت؟\n",
            "قانون فارغ التحصیلی وضع میشود برای دانشگاه شهیدبهشتی.\n",
            "چند واحد لازم است تا فارغ التحصیل شویم؟\n",
            "درس هوش مصنوعی در ترم دوم سال 1401 تعداد واحد درس 3.\n",
            "تعداد واحد مورد نیاز برای فارغ التحصیلی چقدر می‌باشد؟\n",
            "قانون فارغ التحصیلی حداقل تعداد دروس اصلی 4.\n",
            "برای فارغ التحصیلی، تعداد واحد مورد نیاز چقدر است؟\n",
            "قانون فارغ التحصیلی حداقل تعداد دروس اصلی 4.\n",
            "تعداد واحد مورد نیاز برای فارغ التحصیلی چه مقدار است؟\n",
            "قانون فارغ التحصیلی تعداد واحد مورد نیاز برای فارغ التحصیلی 32.\n",
            "Top-1 Accuracy: 10.00%\n",
            "Top-3 Accuracy: 70.00%\n",
            "Top-5 Accuracy: 70.00%\n"
          ]
        }
      ]
    }
  ]
}